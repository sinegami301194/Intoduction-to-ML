#include <opencv2/core.hpp>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/video/tracking.hpp>
#include <string>
#include <iostream>
#include <vector>
#include <ar10/ccmap.h>
#include <ar10/ccdata.h>
#include <warping/warping.h>
#include <ar10/ticker.h>
#include <ocvutils/ocvutils.h>
#include <opencv2/optflow.hpp>

using namespace cv;
using namespace std;

enum class class_flags : int
{
  MACHINERY = 5, // Транспортное средство
  GRASS = 4,// Скошенная трава
  REAPER = 3, // Жатка
  ROLL = 2,// Валок
  BACKGROUND = 0
};

inline int get_pix_value(const Vec3b& pix)
{
  return (pix[0] + pix[1] + pix[2]) / 3;
}

bool fill_out_segmmap(const Mat & segm_image, Mat & out_segmmap)
{
  Ticker t("Function time without forEach: ", NULL, 0);
  Vec3b pix_segm;
  for(int j = 0; j < segm_image.rows; j++)
  {
    const Vec3b *line = segm_image.ptr<Vec3b>(j);
    for (int i = 0; i < segm_image.cols; i++)
    {
      pix_segm = segm_image.at<Vec3b>(j, i);
      if (get_pix_value(pix_segm) == 0)
      {
        rectangle(out_segmmap, Rect(2 * i, 2 * j, 2, 2), Scalar(128, 200, 100));
      }
      if (get_pix_value(pix_segm) == 1)
      {
        rectangle(out_segmmap, Rect(2 * i, 2 * j, 2, 2), Scalar(128, 150, 255));
      }
      if (get_pix_value(pix_segm) == 2)
      {
        rectangle(out_segmmap, Rect(2 * i, 2 * j, 2, 2), Scalar(6, 6, 255));
      }
      if (get_pix_value(pix_segm) == 3)
      {
        rectangle(out_segmmap, Rect(2 * i, 2 * j, 2, 2), Scalar(222, 53, 35)); // Жатка
      }
      if (get_pix_value(pix_segm) == 4)
      {
        rectangle(out_segmmap, Rect(2 * i, 2 * j, 2, 2), Scalar(38, 226, 239)); // Земля
      }
      if (get_pix_value(pix_segm) == 5)
      {
        rectangle(out_segmmap, Rect(2 * i, 2 * j, 2, 2), Scalar(255, 128, 0));
      }
      if (get_pix_value(pix_segm) == 6)
      {
        rectangle(out_segmmap, Rect(2 * i, 2 * j, 2, 2), Scalar(255, 0, 128));
      }
      if (get_pix_value(pix_segm) == 7)
      {
        rectangle(out_segmmap, Rect(2 * i, 2 * j, 2, 2), Scalar(255, 0, 255));
      }
    }
  }
  return true;
}

using FP = std::array<Mat, 2>;

FP flow_parts_fun(const Mat & flow)
{
  FP flow_parts;
  split(flow, flow_parts); // Split 2-channels Mat flow
  return flow_parts;
}

Mat create_image_warped(const Mat& out_segmmap, const Mat& flow)
{
  auto flow_parts = flow_parts_fun(flow); // Get splited 2-channels Mat flow
  Mat image_warped(out_segmmap.rows, out_segmmap.cols, CV_8UC3, Scalar(0, 0, 0));
  int v, u = 0;
  for(int i = 0 ; i < out_segmmap.rows; i++)
  {
    for(int j = 0 ; j < out_segmmap.cols ; j++)
    {
      v = static_cast<int> (round(flow_parts[0].at<float>(i, j))); // Solving optical flow
      u = static_cast<int> (round(flow_parts[1].at<float>(i, j))); // vectors (u, v)
      if (((i + u) < out_segmmap.rows) && (i + u >= 0) && (j + v < out_segmmap.cols) && (j + v >= 0))
      {
        // Warping out_segmmap image by drawing new one with coordinate offset
        image_warped.at<Vec3b>(i + u, j + v) = out_segmmap.at<Vec3b>(i, j);
      }
    }
  }
  return image_warped;
}

int main()
{
  // ===PATH_TO_CONFIG_FILE_AND_SEGMENTATION_OUTPUT_IMAGES===
  string filename_segm_out = "/testdata/tor/out/tor.089/tor.089.015.left.avi.dat/segmentation/tor.089.015.left.%06d.png";

  // ===PREPEARING_FOR_WRITING_VIDEO===
  const string Video_input_PATH = "/testdata/tor/inp/tor.089/tor.089.015.left.avi";
  const string Video_output_PATH = "/home/alpatikov_i/Pictures/OptflowSegm1.avi";
  VideoCapture cap(Video_input_PATH);
  VideoCapture out_seg;  // Creating VideoCapture for segmentation output images
  out_seg.open(filename_segm_out);
  int frame_number = 0;
  int frame_width = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  int frame_height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);
  int DUPLEX_width = 1920;
  int DUPLEX_height = 600;
  VideoWriter video(Video_output_PATH, CV_FOURCC('M', 'J', 'P', 'G'),
                    10, Size(DUPLEX_width, DUPLEX_height), true);

  // ===FRAME_DEFINITION===
  Mat frame1, prvs; // "frame1" is the first frame
  cap >> frame1;

  Mat segm_image; // "segm_image" is the first segmmap frame
  out_seg >> segm_image;
  Mat out_segmmap(frame1.rows, frame1.cols, CV_8UC3, Scalar(0, 0, 0));
  fill_out_segmmap(segm_image, out_segmmap); // Color the segmmap image
  cvtColor(frame1, prvs, COLOR_BGR2GRAY); // Convert to grayscale
  while (true)
  {
    Mat frame, next; // "frame" are the second frame ect.
    cap >> frame;
    cvtColor(frame, next, COLOR_BGR2GRAY); // Convert to grayscale
    Mat flow(out_segmmap.size(), CV_32FC2); // Create 2-channels Mat
    Ptr<cv::optflow::DISOpticalFlow> disof = cv::optflow::createOptFlow_DIS(cv::optflow::DISOpticalFlow::PRESET_MEDIUM);
    disof->calc(prvs, next, flow); // Optflow value calculation
    Mat image_warped = create_image_warped(out_segmmap, flow);
    out_segmmap = image_warped;
    Mat draw = viz_flow(flow, frame, {}, 8); // Visualization Optflow
    
    // ===DISPLAY_TWO_SCREENS===
    cv::Mat win_mat(cv::Size(1920, 600), CV_8UC3);
    draw.copyTo(win_mat(cv::Rect(0, 0, 960, 600)));      // Copy small images into big mat
    out_segmmap.copyTo(win_mat(cv::Rect(960, 0, 960, 600)));
    cv::imshow("Images", win_mat);                          // Display big mat

    // ===WRITE_VIDEO===
    video.write(win_mat);
    char c = (char)waitKey(33);
    if( c == 27 ) break;
  }
  destroyAllWindows();
  return 0;
}
